<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Scrapy框架解析 | 35.32</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Scrapy框架解析</h1><a id="logo" href="/.">35.32</a><p class="description">正如我视笛卡尔的愚蠢的本质</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Scrapy框架解析</h1><div class="post-meta">Oct 26, 2018</div><div class="post-content"><p>Scrapy是一个非常优秀的爬虫框架</p>
<a id="more"></a>
<h3 id="什么是Scrapy？"><a href="#什么是Scrapy？" class="headerlink" title="什么是Scrapy？"></a>什么是Scrapy？</h3><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwml6x6211j30jg0dqdi2.jpg" alt=""></p>
<p><code>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中</code></p>
<h3 id="1-先安装"><a href="#1-先安装" class="headerlink" title="1 . 先安装"></a>1 . <a href="https://www.cnblogs.com/lfoder/p/6565088.html" target="_blank" rel="noopener">先安装</a></h3><h3 id="2-第一个项"><a href="#2-第一个项" class="headerlink" title="2. 第一个项"></a>2. 第一个项</h3><p><code>scrapy startproject tutorial</code><br>直接cmd执行，然后在   c/user/xxx   路径下，出现了一个tutorial 文件夹</p>
<h3 id="Downloader-Middleware-🔍"><a href="#Downloader-Middleware-🔍" class="headerlink" title="Downloader Middleware 🔍"></a>Downloader Middleware 🔍</h3><p>Middleware 是整个scrapy框架中负责网页下载环节的工作，比如说 我们有一个新的项目，并有个该项目下的spider</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HttpbinSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'httpbin'</span></span><br><span class="line">    allowed_domains = [<span class="string">'httpbin.org'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://httpbin.org/get'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.logger.debug(response.text) <span class="comment">#打印响应</span></span><br><span class="line">        self.logger.debug(<span class="string">'Status Code: '</span> + str(response.status))</span><br></pre></td></tr></table></figure>
<p>执行spider</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl httpbin</span><br></pre></td></tr></table></figure>
<p>发现获取到的内容中含有:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">2018-10-27 08:57:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;'downloader/request_bytes': 439,</span><br><span class="line"> 'downloader/request_count': 2,</span><br><span class="line"> 'downloader/request_method_count/GET': 2,</span><br><span class="line"> 'downloader/response_bytes': 768,</span><br><span class="line"> 'downloader/response_count': 2,</span><br><span class="line"> 'downloader/response_status_count/200': 2,</span><br><span class="line"> 'finish_reason': 'finished',</span><br><span class="line"> 'finish_time': datetime.datetime(2018, 10, 27, 0, 57, 9, 949044),</span><br><span class="line"> 'log_count/DEBUG': 5,</span><br><span class="line"> 'log_count/INFO': 7,</span><br><span class="line"> 'response_received_count': 2,</span><br><span class="line"> 'scheduler/dequeued': 1,</span><br><span class="line"> 'scheduler/dequeued/memory': 1,</span><br><span class="line"> 'scheduler/enqueued': 1,</span><br><span class="line"> 'scheduler/enqueued/memory': 1,</span><br><span class="line"> 'start_time': datetime.datetime(2018, 10, 27, 0, 57, 8, 773548)&#125;</span><br></pre></td></tr></table></figure>
<p>其中的<code>headers</code>中的<code>User_Agent</code> 是<code>DownloaderMiddleware</code>并利用 process_request（）方法设置的 User_Agent</p>
<p>我们改动一下 <code>midddlerware.py</code>，添加一个RandomUserAgentMiddleware类 ，如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleware</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">()</span>:</span></span><br><span class="line">        self.user_agent=[</span><br><span class="line">        <span class="number">1.</span>代理</span><br><span class="line">        <span class="number">2.</span>代理</span><br><span class="line">        <span class="number">3.</span>代理</span><br><span class="line">        ]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self,request,spider)</span>:</span></span><br><span class="line">        request.headers[<span class="string">'User_Agent'</span>] = random.choice(self.user_agent)</span><br></pre></td></tr></table></figure>
<p>并且必须在settings.py中取消注释:  <code>DOWNLOADER_MIDDLEWARES</code>并设置成如下内容:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_USERAGENT&#123;</span><br><span class="line">    &apos;scrapydownloadermiddtest.middlewares.RandomUserAgentMiddleware&apos;: 543,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来我们重新运行 Spider，就可以看到 User-Agent 被成功修改为列表中所定义的随机的一个 User-Agent 了</p>
<p> Downloader Middleware 还有<code>process_response()</code>方法。 Downloader对 Request 执行下载之 后会得到 Response，随后 Scrapy 引擎会将 Response 发送回 Spider进行处理。 但是在 Response 被发送 给 Spider 之前，我们同样可以使用<code>process_response()</code>方法对 Response 进行处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def process_response(self, request, response, spider):</span><br><span class="line">    response.status = 201 </span><br><span class="line">    return response`</span><br></pre></td></tr></table></figure>
<p>我们将 response 变量的 status 属性修改为 201 ，随后将 response 返回，这个被修改后的 Response 就会被发送到 Spider。<br>我们再在 Spider里面输出修改后的状态码，在 parse() 方法中添加如下的输出语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.logger.debug（&apos;StatusCode:&apos; + str(response.status))</span><br></pre></td></tr></table></figure>
<p>重新运行之后，控制台输出了如下内容：<br><code>[httpbin] DEBUG: Status Code: 201</code></p>
<p> Response 的状态码成功修改了。<br>因此要想对 Response 进行后处理，就可以借助于<code>process_response()</code>方法</p>
<h3 id="SpiderMiddleware-用法🏳‍🌈"><a href="#SpiderMiddleware-用法🏳‍🌈" class="headerlink" title="SpiderMiddleware 用法🏳‍🌈"></a>SpiderMiddleware 用法🏳‍🌈</h3><p>Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。更多内容请看 Spider中间件(Middleware)<br>一句话总结就是：<code>处理解析部</code></p>
<h3 id="Item-PipeLine-用法🐱‍👓"><a href="#Item-PipeLine-用法🐱‍👓" class="headerlink" title="Item PipeLine 用法🐱‍👓"></a>Item PipeLine 用法🐱‍👓</h3><p>当spider爬取到item后，它被发送到项目管道（Item Pipeline），通过几个组件按顺序进行处理。每一个Item Pipeline是一个实现了简单方法的Python类，它接收到一个item并对其执行一个操作，也要决定该item是否应该继续通过管道，或者被丢弃，不再进行处理。</p>
<p><code>简单来说，我们通过爬虫爬取的项目，先交给项目管道，项目管道把数据处理处理(删除一些啦，存到mongodb啦)产生新的item</code></p>
<p><strong>Item Pipeline典型的用途是：</strong><br>1.清理HTML数据<br>2.验证爬取的数据(检查items是否包含某些字段)<br>3.检查副本(并删除它们)<br>4.将item数据存储在数据库中</p>
<p><code>每个Item Pipeline都是一个Python类</code>，它必须实现以下方法:</p>
<p><strong>process_item(self, item, spider)</strong></p>
<p>这个方法可以被每个Item Pipeline调用，process_item()必须是:返回一个字典类型数据、返回一个条目(或任何子类)对象，返回一个 Twisted Deferred 或者DropItem异常，丢弃的item不再由进一步的Item Pipeline处理。<br>参数含义：<br>item： Item对象或字典，爬取的item<br>spider：spider对象，爬取了这个item的spider<br>此外，他们还可以实现以下方法:</p>
<p><strong>open_spider(self, spider)</strong> -&gt;当spider打开时，函数就会被调用，spider参数含义：被打开的spider<br><strong>close_spider(self, spider)</strong>  -&gt;当spider关闭是，函数会被调用<br><strong>from_crawler(cls, crawler)</strong>  -&gt; 如果存在，这个类方法被调用来从一个Crawler创建一个spider实例。它必须返回管道的一个新实例，Crawler对象提供对所有的scrapy核心组件的访问，比如设置和信号;这是管道访问它们并将其功能连接到scrapy的一种方式。</p>
<hr>
<p>参考链接:</p>
<p>​              <a href="https://blog.csdn.net/xnby/article/details/52297047" target="_blank" rel="noopener">Scrapy进阶,middleware的使用</a></p>
<p>​              <a href="http://blog.51cto.com/linuxliu/2068601?wx" target="_blank" rel="noopener">运维学Python之爬虫高级篇</a></p>
<p>​              </p>
</div><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-nav"><a class="pre" href="/2018/10/28/Ajax和XHR/">Ajax和XHR</a><a class="next" href="/2018/10/21/nuisance/">不该死的人，还活着</a></div><div id="container"></div><link rel="stylesheet" href="https://35p32.github.io/gitment/style/default.css"><script src="https://35p32.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: '35p32## Your GitHub ID, e.g. username',
  repo: 'cogito',
  oauth: {
    client_id: 'e40571b1a5ccce57c5c4## GitHub client ID, e.g. 75752dafe7907a897619',
    client_secret: 'e7020e3140ee19bf8bea9bceece0133736bc5057',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/前端基础/" style="font-size: 15px;">前端基础</a> <a href="/tags/话/" style="font-size: 15px;">话</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/28/Scrapy框架(二)/">Scrapy框架(二)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/28/Ajax和XHR/">Ajax和XHR</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/26/Scrapy/">Scrapy框架解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/21/nuisance/">不该死的人，还活着</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/20/wechatspider/">qppium模拟---微信朋友圈</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/20/MongoDB/">MongoDB</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/08/sougoupachong/">写在学习代理池和cookie池之后</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/07/python_new/">python の __new__()</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/07/photo/">关于海</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/04/huadongpojie/">GEETEST滑动验证码破解</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.baidu.com/s?ie=UTF-8&amp;wd=vps%E6%90%AD%E5%BB%BA" title="眼" target="_blank">眼</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">35.32.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>