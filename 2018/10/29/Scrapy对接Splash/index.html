<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Scrapy对接Splash | 35.32</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Scrapy对接Splash</h1><a id="logo" href="/.">35.32</a><p class="description">这些表象就是崇高和滑稽</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Scrapy对接Splash</h1><div class="post-meta">Oct 29, 2018</div><div class="post-content"><p>抓取淘宝商品是一种抓取JavaScript渲染页面的方式，除了使用Selenium还有<code>splash</code>同样可以达到同样的功能</p>
<a id="more"></a>
<p>老样子，新建一个<code>项目+爬虫</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject scrapysplashtes</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider taobao www.taobao.com</span><br></pre></td></tr></table></figure>
<p>制造者已经为scrapy制定了完备的splash接口，我们只需:</p>
<h2 id="在settings中配置关于splash的相关设置"><a href="#在settings中配置关于splash的相关设置" class="headerlink" title="在settings中配置关于splash的相关设置"></a>在settings中配置关于splash的相关设置</h2><p>–&gt;修改settings.py，首先将SPLASH_URL配置一下，在这里我们的Splash是在本地运行的，所以可以直接配置本地的地址</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">'http://localhost:8050'</span></span><br></pre></td></tr></table></figure>
<p>–&gt; 接下来我们还需要配置几个Middleware</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>👆配置了三个Downloader Middleware和一个Spider Middleware，这是ScrapySplash的核心部分，配置了它们我们就可以对接Splash进行页面抓取，在这里我们不再需要像对接Selenium那样实现一个Downloader Middleware，ScrapySplash库都为我们准备好了，直接配置即可.</p>
<p>着还需要配置一个去重的类DUPEFILTER_CLASS</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br></pre></td></tr></table></figure>
<p>最后还需要配置一个Cache存储HTTPCACHE_STORAGE</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy_splash.SplashAwareFSCacheStorage'</span></span><br></pre></td></tr></table></figure>
<p><em>完成！</em> </p>
<hr>
<p>本节我们要做的抓取是淘宝商品信息，涉及到页面加载等待、模拟点击翻页等操作，所以这里就需要Lua脚本来实现了，所以我们在这里可以首先定义一个Lua脚本，来实现页面加载、模拟点击翻页的功能<a href="https://www.runoob.com/lua/lua-tutorial.html" target="_blank" rel="noopener">关于Lua</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">function main(splash, args)</span><br><span class="line">  args = &#123;</span><br><span class="line">    url=<span class="string">"https://s.taobao.com/search?q=iPad"</span>,</span><br><span class="line">    wait=<span class="number">5</span>,</span><br><span class="line">    page=<span class="number">5</span></span><br><span class="line">  &#125;</span><br><span class="line">  splash.images_enabled = false</span><br><span class="line">  <span class="keyword">assert</span>(splash:go(args.url))</span><br><span class="line">  <span class="keyword">assert</span>(splash:wait(args.wait))</span><br><span class="line">  js = string.format(<span class="string">"document.querySelector('#mainsrp-pager div.form &gt; input').value=%d;document.querySelector('#mainsrp-pager div.form &gt; span.btn.J_Submit').click()"</span>, args.page)</span><br><span class="line">  splash:evaljs(js)</span><br><span class="line">  <span class="keyword">assert</span>(splash:wait(args.wait))</span><br><span class="line">  <span class="keyword">return</span> splash:html()</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>lua是一种脚本语言，我们写出一段<code>lua脚本</code>之后，对接到SplashRequest中，就可使用</p>
<p>最终taobao.py结果如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Spider</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">from</span> scrapysplashtest.items <span class="keyword">import</span> ProductItem</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line">script = <span class="string">""" #lua脚本</span></span><br><span class="line"><span class="string">function main(splash, args)</span></span><br><span class="line"><span class="string">  splash.images_enabled = false</span></span><br><span class="line"><span class="string">  assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">  assert(splash:wait(args.wait))</span></span><br><span class="line"><span class="string">  js = string.format("document.querySelector('#mainsrp-pager div.form &gt; input').value=%d;document.querySelector('#mainsrp-pager div.form &gt; span.btn.J_Submit').click()", args.page)</span></span><br><span class="line"><span class="string">  splash:evaljs(js)</span></span><br><span class="line"><span class="string">  assert(splash:wait(args.wait))</span></span><br><span class="line"><span class="string">  return splash:html()</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaobaoSpider</span><span class="params">(Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'taobao'</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.taobao.com'</span>]</span><br><span class="line">    base_url = <span class="string">'https://s.taobao.com/search?q='</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> keyword <span class="keyword">in</span> self.settings.get(<span class="string">'KEYWORD'</span>):</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,self.settings.get(<span class="string">'MAX_PAGE'</span>)+<span class="number">1</span>):</span><br><span class="line">                url = self.base_url + quote(keyword)</span><br><span class="line">                <span class="keyword">yield</span> SelfshResponse(url,callback = self.parse,endpoint=<span class="string">'execute'</span>,args=&#123;<span class="string">'lua_source'</span>:script,<span class="string">'page'</span>:page,<span class="string">'wait'</span>:<span class="number">7</span>&#125;)</span><br></pre></td></tr></table></figure>
<p><code>把Lua脚本定义成长字符串</code>，通过<code>SplashRequest 的 args</code>来传递参数，另外args参数里还有一个lua_source字段用于指定Lua脚本内容，这样我们就成功构造了一个SplashRequest，对接Splash的工作就完成了</p>
<p>接下来的工作就很正常了</p>
<p>settings中设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">'http://192.168.99.100:8050'</span> <span class="comment">#而非http://localhost:8050</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#去重的类DUPEFILTER_CLASS</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br><span class="line"><span class="comment">#一个Cache存储HTTPCACHE_STORAGE</span></span><br><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy_splash.SplashAwareFSCacheStorage'</span></span><br></pre></td></tr></table></figure>
<p><em>此处必须解释一下，曾在这里卡到了第一句话上，崔庆才老师设置的是后者，这和docker开的端口有关</em></p>
<p>首先打开<code>virtualbox</code>，开启<code>default</code>服务，同时打开<code>docker quickstart terminal</code></p>
<p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwr5oncmf5j30lv0a3mx9.jpg" alt=""></p>
<p>/<em>如果docker出现什么报错，就先解决那个问题,刚接触docker，感觉这个东西坑很深</em>/ ,<br>/<em>过程中请保持virtualbox的default打开</em>/<br> 我们清楚的看到<code>docker被配置为使用IP 192.168.99.100的默认机器</code></p>
<p>所以，使用docker必须splash_url改为<code>http://192.168.99.100:8050</code></p>
<p>运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl taobao</span><br></pre></td></tr></table></figure>
<p>爬虫的速度将是惊人的。</p>
</div><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-nav"><a class="pre" href="/2018/10/31/Scrapy框架通用爬虫/">完美哈希</a><a class="next" href="/2018/10/28/Scrapy框架(二)/">Scrapy框架(二)</a></div><div id="container"></div><link rel="stylesheet" href="https://35p32.github.io/gitment/style/default.css"><script src="https://35p32.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: '35p32## Your GitHub ID, e.g. username',
  repo: 'cogito',
  oauth: {
    client_id: 'e40571b1a5ccce57c5c4## GitHub client ID, e.g. 75752dafe7907a897619',
    client_secret: 'e7020e3140ee19bf8bea9bceece0133736bc5057',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/complier/" style="font-size: 15px;">complier</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/C/" style="font-size: 15px;">C++</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/lisp/" style="font-size: 15px;">lisp</a> <a href="/tags/前端基础/" style="font-size: 15px;">前端基础</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/话/" style="font-size: 15px;">话</a> <a href="/tags/ACM/" style="font-size: 15px;">ACM</a> <a href="/tags/MachineLearning/" style="font-size: 15px;">MachineLearning</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/02/28/Java备忘录Ⅲ/">Java备忘录Ⅲ</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/02/原谅我不明白你的悲伤/">旧病</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/16/Java备忘录Ⅰ/">Java备忘录Ⅰ</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/31/Lisp扫盲/">Lisp扫盲</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/25/机器学习日记(二)/">机器学习日记_2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/机器学习日记(一)/">机器学习日记_1</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/11/Re-NFA-DFA-词法分析器代码/">词法分析器</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/特殊的dp/">特殊的dp</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/仓库/">仓库</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/09/三类背包/">三类背包</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.baidu.com/s?ie=UTF-8&amp;wd=vps%E6%90%AD%E5%BB%BA" title="眼" target="_blank">眼</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">35.32.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>