<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>35.32</title>
  
  <subtitle>正如我视笛卡尔的愚蠢的本质</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="httpsp://yoursite.com/"/>
  <updated>2018-11-04T10:17:32.002Z</updated>
  <id>httpsp://yoursite.com/</id>
  
  <author>
    <name>槨冧</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>有限状态自动机</title>
    <link href="httpsp://yoursite.com/2018/11/04/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E8%87%AA%E5%8A%A8%E6%9C%BA/"/>
    <id>httpsp://yoursite.com/2018/11/04/有限状态自动机/</id>
    <published>2018-11-04T08:59:36.185Z</published>
    <updated>2018-11-04T10:17:32.002Z</updated>
    
    <content type="html"><![CDATA[<p>总结</p><a id="more"></a><p>举例子如图:</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fww66hr1b9j30vz0mytbc.jpg" alt=""></p><p>如图 <code>(q0,a)-&gt;q1,(q0,b)-&gt;q0</code> 这就叫做状态转移函数，咋解释呢？ </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">黄色圆形代表一个一个状态，内部数字就是状态对应的编号</span><br><span class="line">q0 接受 a 到达 q1 </span><br><span class="line">q0 接受 b 到达 q0</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure><p>然后就像你看到的，把这些状态(<code>小括号包括住的</code>)积攒在一起，就是我们的图1的 <code>S</code>也叫<code>状态集</code></p><p>这些  <code>从某个状态到达另外一个状态</code> 的过程，本身可以称作一个函数，这些函数的集合叫做，转移函数集合。</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fww682bj7lj30w00ka40t.jpg" alt=""></p><p><code>有限状态自动机：</code></p><ol><li>非确定有限状态自动机(NFA)</li><li>确定的有限状态自动机(DFA)</li></ol><p>我们第一个图就是个确定的，来看看一个不确定的:</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fww6kumrtij30u00n5dhr.jpg" alt=""></p><p>这个为什么叫不确定的状态自动机？  你看看， 加入我们给 <code>q0 传递 a</code>  ,你能知道 q0到q0，还是q0到q1？？ 你是不确定的，所以含有这种构造的自动机就叫<code>NFA</code></p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>问？在NFA中，我们在初始状态为 <code>q0</code> 时，传入 字符串s=<code>&quot;a&quot;</code>,请问对于NFA，它可以接受吗？</p><p>答：可以，尽管q0 有可能接受 <code>a</code>后还是状态本身，但只要有一条路可转移走，NFA在经过<code>遍历</code> 后，就可以找到了！</p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>我们该怎样把这么一个抽象的自动机通过代码实现呢？</p><p>我们其中一个办法就是，图的邻接矩阵实现。</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fww6umswk8j30sq0nnwg3.jpg" alt=""></p><p>解释：0接受a变为1；0接受b变成0 以此类推</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结&lt;/p&gt;
    
    </summary>
    
    
      <category term="complier" scheme="httpsp://yoursite.com/tags/complier/"/>
    
  </entry>
  
  <entry>
    <title>从微博spider详解Scrapy</title>
    <link href="httpsp://yoursite.com/2018/11/03/%E4%BB%8E%E5%BE%AE%E5%8D%9Aspider%E8%AF%A6%E8%A7%A3Scrapy/"/>
    <id>httpsp://yoursite.com/2018/11/03/从微博spider详解Scrapy/</id>
    <published>2018-11-03T13:25:57.811Z</published>
    <updated>2018-11-03T13:25:57.818Z</updated>
    
    <content type="html"><![CDATA[<p>本文旨在彻底剖析Scrapy爬虫框架</p><a id="more"></a><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>针对: <code>https://m.weibo.cn</code> 爬取新浪微博用户的公开基本信息，如用户昵称、头像、用户的关注、粉丝列表以 及发布的微博等，这些信息抓取之后保存至 MongoDB。</p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>情确保前文所讲的代理池、 Cookies 池已经实现并可以正常运行，安装 Scrapy、 PyMongo 库，如 没有安装可以参考前文内容</p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>针对请求解析不再过多阐述， </p><p>从XHR分析可知，请求类型为Get ,因此，模仿创造请求。</p><p><code>https://m.weibo.cn/api/container/getlndex?contaiaerid= 231 051二followers-_1916655407 &amp;luicode= I 00000 l l&amp;lfid= I 005051916655407 &amp;featurecode=20000320&amp;type =uid&amp;value= 1916655407 &amp;page=2</code></p><p>其中最主要的参数就是 containerid 和 page。 有了这两个参数，我们同样可以获取请求结果。 我 们可以将接口精简为  <a href="https://m.weibo.cn/api/container/getIndex?containerid=231051-_followers-_1916655407&amp;page=2" target="_blank" rel="noopener">https://m.weibo.cn/api/container/getIndex?containerid=231051-_followers-_1916655407&amp;page=2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文旨在彻底剖析Scrapy爬虫框架&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>C++ template —— 模板基础（一）</title>
    <link href="httpsp://yoursite.com/2018/11/01/C++-template-%E2%80%94%E2%80%94-%E6%A8%A1%E6%9D%BF%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>httpsp://yoursite.com/2018/11/01/C++-template-——-模板基础（一）/</id>
    <published>2018-11-01T03:33:01.175Z</published>
    <updated>2018-11-01T03:48:52.276Z</updated>
    
    <content type="html"><![CDATA[<p>C++的魅力，实在使人难以忘却。</p><a id="more"></a><p><a href="https://www.cnblogs.com/yyxt/category/772515.html" target="_blank" rel="noopener">拜读</a></p><p>本文转载于: <a href="https://www.cnblogs.com/yyxt/" target="_blank" rel="noopener">博客园_小天</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++的魅力，实在使人难以忘却。&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++" scheme="httpsp://yoursite.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>完美哈希</title>
    <link href="httpsp://yoursite.com/2018/10/31/Scrapy%E6%A1%86%E6%9E%B6%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB/"/>
    <id>httpsp://yoursite.com/2018/10/31/Scrapy框架通用爬虫/</id>
    <published>2018-10-31T01:53:27.982Z</published>
    <updated>2018-11-01T16:15:39.315Z</updated>
    
    <content type="html"><![CDATA[<p>通过构造完美哈希，可以在O(1)时间内实现关键字的查询。</p><p> 关键字表算法: 通过构造完美哈希，可以在O(1)时间内实现关键字的查询.</p><a id="more"></a><p><a href="https://www.cnblogs.com/gaochundong/p/hashtable_and_perfect_hashing.html" target="_blank" rel="noopener">哈希综述</a> </p><p><a href="https://www.ibm.com/developerworks/cn/linux/l-gperf.html" target="_blank" rel="noopener">gperf算法</a></p><p>PHF(<em>Perfect Hash Function</em>)和MPHF(<em>Minimal Perfect Hash Function</em>)生成算法：</p><p>  <a href="http://homepages.dcc.ufmg.br/~nivio/papers/wea05.pdf" target="_blank" rel="noopener">A Practical Minimal Perfect Hashing Method</a></p><p>  <a href="http://homepages.dcc.ufmg.br/~nivio/papers/tr06.pdf" target="_blank" rel="noopener">An Approach for Minimal Perfect Hash Functions for Very Large Databases</a></p><p>  <a href="http://homepages.dcc.ufmg.br/~nivio/papers/tr004_04.ps" target="_blank" rel="noopener">A New algorithm for constructing minimal perfect hash functions</a></p><p>  <a href="http://citeseer.ist.psu.edu/czech92optimal.html" target="_blank" rel="noopener">A optimal algorithm to generating minimal perfect hash function</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过构造完美哈希，可以在O(1)时间内实现关键字的查询。&lt;/p&gt;
&lt;p&gt; 关键字表算法: 通过构造完美哈希，可以在O(1)时间内实现关键字的查询.&lt;/p&gt;
    
    </summary>
    
    
      <category term="complier" scheme="httpsp://yoursite.com/tags/complier/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy对接Splash</title>
    <link href="httpsp://yoursite.com/2018/10/29/Scrapy%E5%AF%B9%E6%8E%A5Splash/"/>
    <id>httpsp://yoursite.com/2018/10/29/Scrapy对接Splash/</id>
    <published>2018-10-29T11:19:24.631Z</published>
    <updated>2018-10-31T01:44:48.609Z</updated>
    
    <content type="html"><![CDATA[<p>抓取淘宝商品是一种抓取JavaScript渲染页面的方式，除了使用Selenium还有<code>splash</code>同样可以达到同样的功能</p><a id="more"></a><p>老样子，新建一个<code>项目+爬虫</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject scrapysplashtes</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider taobao www.taobao.com</span><br></pre></td></tr></table></figure><p>制造者已经为scrapy制定了完备的splash接口，我们只需:</p><h2 id="在settings中配置关于splash的相关设置"><a href="#在settings中配置关于splash的相关设置" class="headerlink" title="在settings中配置关于splash的相关设置"></a>在settings中配置关于splash的相关设置</h2><p>–&gt;修改settings.py，首先将SPLASH_URL配置一下，在这里我们的Splash是在本地运行的，所以可以直接配置本地的地址</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">'http://localhost:8050'</span></span><br></pre></td></tr></table></figure><p>–&gt; 接下来我们还需要配置几个Middleware</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>👆配置了三个Downloader Middleware和一个Spider Middleware，这是ScrapySplash的核心部分，配置了它们我们就可以对接Splash进行页面抓取，在这里我们不再需要像对接Selenium那样实现一个Downloader Middleware，ScrapySplash库都为我们准备好了，直接配置即可.</p><p>着还需要配置一个去重的类DUPEFILTER_CLASS</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br></pre></td></tr></table></figure><p>最后还需要配置一个Cache存储HTTPCACHE_STORAGE</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy_splash.SplashAwareFSCacheStorage'</span></span><br></pre></td></tr></table></figure><p><em>完成！</em> </p><hr><p>本节我们要做的抓取是淘宝商品信息，涉及到页面加载等待、模拟点击翻页等操作，所以这里就需要Lua脚本来实现了，所以我们在这里可以首先定义一个Lua脚本，来实现页面加载、模拟点击翻页的功能<a href="https://www.runoob.com/lua/lua-tutorial.html" target="_blank" rel="noopener">关于Lua</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">function main(splash, args)</span><br><span class="line">  args = &#123;</span><br><span class="line">    url=<span class="string">"https://s.taobao.com/search?q=iPad"</span>,</span><br><span class="line">    wait=<span class="number">5</span>,</span><br><span class="line">    page=<span class="number">5</span></span><br><span class="line">  &#125;</span><br><span class="line">  splash.images_enabled = false</span><br><span class="line">  <span class="keyword">assert</span>(splash:go(args.url))</span><br><span class="line">  <span class="keyword">assert</span>(splash:wait(args.wait))</span><br><span class="line">  js = string.format(<span class="string">"document.querySelector('#mainsrp-pager div.form &gt; input').value=%d;document.querySelector('#mainsrp-pager div.form &gt; span.btn.J_Submit').click()"</span>, args.page)</span><br><span class="line">  splash:evaljs(js)</span><br><span class="line">  <span class="keyword">assert</span>(splash:wait(args.wait))</span><br><span class="line">  <span class="keyword">return</span> splash:html()</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>lua是一种脚本语言，我们写出一段<code>lua脚本</code>之后，对接到SplashRequest中，就可使用</p><p>最终taobao.py结果如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Spider</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">from</span> scrapysplashtest.items <span class="keyword">import</span> ProductItem</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line">script = <span class="string">""" #lua脚本</span></span><br><span class="line"><span class="string">function main(splash, args)</span></span><br><span class="line"><span class="string">  splash.images_enabled = false</span></span><br><span class="line"><span class="string">  assert(splash:go(args.url))</span></span><br><span class="line"><span class="string">  assert(splash:wait(args.wait))</span></span><br><span class="line"><span class="string">  js = string.format("document.querySelector('#mainsrp-pager div.form &gt; input').value=%d;document.querySelector('#mainsrp-pager div.form &gt; span.btn.J_Submit').click()", args.page)</span></span><br><span class="line"><span class="string">  splash:evaljs(js)</span></span><br><span class="line"><span class="string">  assert(splash:wait(args.wait))</span></span><br><span class="line"><span class="string">  return splash:html()</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaobaoSpider</span><span class="params">(Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'taobao'</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.taobao.com'</span>]</span><br><span class="line">    base_url = <span class="string">'https://s.taobao.com/search?q='</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> keyword <span class="keyword">in</span> self.settings.get(<span class="string">'KEYWORD'</span>):</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,self.settings.get(<span class="string">'MAX_PAGE'</span>)+<span class="number">1</span>):</span><br><span class="line">                url = self.base_url + quote(keyword)</span><br><span class="line">                <span class="keyword">yield</span> SelfshResponse(url,callback = self.parse,endpoint=<span class="string">'execute'</span>,args=&#123;<span class="string">'lua_source'</span>:script,<span class="string">'page'</span>:page,<span class="string">'wait'</span>:<span class="number">7</span>&#125;)</span><br></pre></td></tr></table></figure><p><code>把Lua脚本定义成长字符串</code>，通过<code>SplashRequest 的 args</code>来传递参数，另外args参数里还有一个lua_source字段用于指定Lua脚本内容，这样我们就成功构造了一个SplashRequest，对接Splash的工作就完成了</p><p>接下来的工作就很正常了</p><p>settings中设置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">'http://192.168.99.100:8050'</span> <span class="comment">#而非http://localhost:8050</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashCookiesMiddleware'</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">'scrapy_splash.SplashMiddleware'</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'scrapy_splash.SplashDeduplicateArgsMiddleware'</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#去重的类DUPEFILTER_CLASS</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">'scrapy_splash.SplashAwareDupeFilter'</span></span><br><span class="line"><span class="comment">#一个Cache存储HTTPCACHE_STORAGE</span></span><br><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy_splash.SplashAwareFSCacheStorage'</span></span><br></pre></td></tr></table></figure><p><em>此处必须解释一下，曾在这里卡到了第一句话上，崔庆才老师设置的是后者，这和docker开的端口有关</em></p><p>首先打开<code>virtualbox</code>，开启<code>default</code>服务，同时打开<code>docker quickstart terminal</code></p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwr5oncmf5j30lv0a3mx9.jpg" alt=""></p><p>/<em>如果docker出现什么报错，就先解决那个问题,刚接触docker，感觉这个东西坑很深</em>/ ,<br>/<em>过程中请保持virtualbox的default打开</em>/<br> 我们清楚的看到<code>docker被配置为使用IP 192.168.99.100的默认机器</code></p><p>所以，使用docker必须splash_url改为<code>http://192.168.99.100:8050</code></p><p>运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl taobao</span><br></pre></td></tr></table></figure><p>爬虫的速度将是惊人的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;抓取淘宝商品是一种抓取JavaScript渲染页面的方式，除了使用Selenium还有&lt;code&gt;splash&lt;/code&gt;同样可以达到同样的功能&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy框架(二)</title>
    <link href="httpsp://yoursite.com/2018/10/28/Scrapy%E6%A1%86%E6%9E%B6(%E4%BA%8C)/"/>
    <id>httpsp://yoursite.com/2018/10/28/Scrapy框架(二)/</id>
    <published>2018-10-28T12:00:53.156Z</published>
    <updated>2018-10-28T12:40:57.993Z</updated>
    
    <content type="html"><![CDATA[<p>从实例中看scrapy框架中各部分的功能</p><p><img src="https://wx1.sinaimg.cn/mw690/6c3e6b13gy1fwjoq4i6rcj20zk0wk4qp.jpg" alt=""></p><a id="more"></a><p>取的目标网站为：<a href="https://image.so.com" target="_blank" rel="noopener">https://image.so.com</a></p><p>打开浏览器开发者工具，过滤器切换到XHR选项,下拉页面，可以看到下面就会呈现许多Ajax请求</p><p><img src="https://ask.qcloudimg.com/http-save/developer-news/q8remsppeb.jpeg" alt=""></p><p><img src="https://ask.qcloudimg.com/http-save/developer-news/7xvqjdt74l.jpeg" alt=""></p><p>返回格式是JSON。其中字段就是一张张图片的详情信息，包含了30张图片的ID、名称、链接、缩略图等信息。另外观察Ajax请求的参数信息，有一个参数一直在变化，这个参数很明显就是偏移量。当为30时，返回的是前30张图片，sn为60时，返回的就是第31~60张图片。</p><p>实际上，我们向浏览器发送ajax请求，我们从网址上，即被url编码的params列表，比如：</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwo4qvh794j311b0bu75u.jpg" alt=""></p><p>我们看到了:</p><ol><li>ch</li><li>sn</li><li>listtype</li><li>temp</li></ol><p>所以所谓的参数列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">params&#123;</span><br><span class="line">    xxx</span><br><span class="line">    xxx</span><br><span class="line">    xxx</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只用含有这几个参数就可以了。</p><hr><p>分析完毕后，开始新建项目.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject images360</span><br></pre></td></tr></table></figure><p>cd 到这个项目的 spiders项目下，创建一个爬虫名为<code>images360</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider images360  images.so.com</span><br></pre></td></tr></table></figure><p><strong>有了爬虫，接下来应该做什么？</strong>🧐</p><h2 id="第一"><a href="#第一" class="headerlink" title="第一"></a>第一</h2><p>肯定是要对spiders处理，我们进入spiders文件夹里面的<code>images.py</code>里看，爬虫有了，方法要我们创建。</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwo522pfeyj30ld0ic0ti.jpg" alt=""></p><p>这里的爬虫有三个部分:</p><p><em>1</em> :  <code>name</code>是爬虫名，<code>allowed_domain</code>是访问的域名，<code>start_urls</code>的含义是过滤爬取的域名，在插件OffsiteMiddleware启用的情况下（默认是启用的），不在此允许范围内的域名就会被过滤，而不会进行爬取,</p><p>请注意,以上三个部分，都是在我们第二个命令执行时，S框架自动生成的，我们不用动.</p><p><em>2</em>: <code>start_requests</code>就算是我们熟悉的通过循环向浏览器发送ajax请求，<code>parse</code>是对返回的response进行解析，我们知道，基本的爬虫实现都是在这里做的。</p><p>我们重点关注其他部分，也就是框架的其他环节</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">item</span><br><span class="line">middleware</span><br><span class="line">settings</span><br><span class="line">piplines</span><br></pre></td></tr></table></figure><p><code>item</code>:打个比方，你想要你爬到的东西的什么部分？你希望他们以什么样子交给你？</p><p>​               我想要网站图片的id,链接地址，主题，缩略图,我想要它们以一个字典的形式呈交给我</p><p>​              那么，item.py就是干这个的.​           </p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwo5bmi8y8j30h80ai3ym.jpg" alt=""></p><p><code>middleware</code>:中间件，作用是修改代理ip啦，访问浏览器的user_agent啦，<a href="https://blog.csdn.net/yancey_blog/article/details/53896092" target="_blank" rel="noopener">了解一下</a> ,此例不用middleware     </p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwo6sjw5saj30mq0p80ua.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从实例中看scrapy框架中各部分的功能&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://wx1.sinaimg.cn/mw690/6c3e6b13gy1fwjoq4i6rcj20zk0wk4qp.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Ajax和XHR</title>
    <link href="httpsp://yoursite.com/2018/10/28/Ajax%E5%92%8CXHR/"/>
    <id>httpsp://yoursite.com/2018/10/28/Ajax和XHR/</id>
    <published>2018-10-28T02:29:32.444Z</published>
    <updated>2018-10-28T02:29:32.451Z</updated>
    
    <content type="html"><![CDATA[<p>  ajax是asynchronous javascript and XML的简写</p><a id="more"></a><p><a href="https://www.cnblogs.com/xiaohuochai/p/6036475.html" target="_blank" rel="noopener">拜读</a></p><p><br><br><br><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  ajax是asynchronous javascript and XML的简写&lt;/p&gt;
    
    </summary>
    
    
      <category term="前端基础" scheme="httpsp://yoursite.com/tags/%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy框架解析</title>
    <link href="httpsp://yoursite.com/2018/10/26/Scrapy/"/>
    <id>httpsp://yoursite.com/2018/10/26/Scrapy/</id>
    <published>2018-10-25T16:14:46.767Z</published>
    <updated>2018-10-28T12:24:44.089Z</updated>
    
    <content type="html"><![CDATA[<p>Scrapy是一个非常优秀的爬虫框架</p><a id="more"></a><h3 id="什么是Scrapy？"><a href="#什么是Scrapy？" class="headerlink" title="什么是Scrapy？"></a>什么是Scrapy？</h3><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwml6x6211j30jg0dqdi2.jpg" alt=""></p><p><code>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中</code></p><h3 id="1-先安装"><a href="#1-先安装" class="headerlink" title="1 . 先安装"></a>1 . <a href="https://www.cnblogs.com/lfoder/p/6565088.html" target="_blank" rel="noopener">先安装</a></h3><h3 id="2-第一个项"><a href="#2-第一个项" class="headerlink" title="2. 第一个项"></a>2. 第一个项</h3><p><code>scrapy startproject tutorial</code><br>直接cmd执行，然后在   c/user/xxx   路径下，出现了一个tutorial 文件夹</p><h3 id="Downloader-Middleware-🔍"><a href="#Downloader-Middleware-🔍" class="headerlink" title="Downloader Middleware 🔍"></a>Downloader Middleware 🔍</h3><p>Middleware 是整个scrapy框架中负责网页下载环节的工作，比如说 我们有一个新的项目，并有个该项目下的spider</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HttpbinSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'httpbin'</span></span><br><span class="line">    allowed_domains = [<span class="string">'httpbin.org'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://httpbin.org/get'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.logger.debug(response.text) <span class="comment">#打印响应</span></span><br><span class="line">        self.logger.debug(<span class="string">'Status Code: '</span> + str(response.status))</span><br></pre></td></tr></table></figure><p>执行spider</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl httpbin</span><br></pre></td></tr></table></figure><p>发现获取到的内容中含有:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">2018-10-27 08:57:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;'downloader/request_bytes': 439,</span><br><span class="line"> 'downloader/request_count': 2,</span><br><span class="line"> 'downloader/request_method_count/GET': 2,</span><br><span class="line"> 'downloader/response_bytes': 768,</span><br><span class="line"> 'downloader/response_count': 2,</span><br><span class="line"> 'downloader/response_status_count/200': 2,</span><br><span class="line"> 'finish_reason': 'finished',</span><br><span class="line"> 'finish_time': datetime.datetime(2018, 10, 27, 0, 57, 9, 949044),</span><br><span class="line"> 'log_count/DEBUG': 5,</span><br><span class="line"> 'log_count/INFO': 7,</span><br><span class="line"> 'response_received_count': 2,</span><br><span class="line"> 'scheduler/dequeued': 1,</span><br><span class="line"> 'scheduler/dequeued/memory': 1,</span><br><span class="line"> 'scheduler/enqueued': 1,</span><br><span class="line"> 'scheduler/enqueued/memory': 1,</span><br><span class="line"> 'start_time': datetime.datetime(2018, 10, 27, 0, 57, 8, 773548)&#125;</span><br></pre></td></tr></table></figure><p>其中的<code>headers</code>中的<code>User_Agent</code> 是<code>DownloaderMiddleware</code>并利用 process_request（）方法设置的 User_Agent</p><p>我们改动一下 <code>midddlerware.py</code>，添加一个RandomUserAgentMiddleware类 ，如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleware</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">()</span>:</span></span><br><span class="line">        self.user_agent=[</span><br><span class="line">        <span class="number">1.</span>代理</span><br><span class="line">        <span class="number">2.</span>代理</span><br><span class="line">        <span class="number">3.</span>代理</span><br><span class="line">        ]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self,request,spider)</span>:</span></span><br><span class="line">        request.headers[<span class="string">'User_Agent'</span>] = random.choice(self.user_agent)</span><br></pre></td></tr></table></figure><p>并且必须在settings.py中取消注释:  <code>DOWNLOADER_MIDDLEWARES</code>并设置成如下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_USERAGENT&#123;</span><br><span class="line">    &apos;scrapydownloadermiddtest.middlewares.RandomUserAgentMiddleware&apos;: 543,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来我们重新运行 Spider，就可以看到 User-Agent 被成功修改为列表中所定义的随机的一个 User-Agent 了</p><p> Downloader Middleware 还有<code>process_response()</code>方法。 Downloader对 Request 执行下载之 后会得到 Response，随后 Scrapy 引擎会将 Response 发送回 Spider进行处理。 但是在 Response 被发送 给 Spider 之前，我们同样可以使用<code>process_response()</code>方法对 Response 进行处理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def process_response(self, request, response, spider):</span><br><span class="line">    response.status = 201 </span><br><span class="line">    return response`</span><br></pre></td></tr></table></figure><p>我们将 response 变量的 status 属性修改为 201 ，随后将 response 返回，这个被修改后的 Response 就会被发送到 Spider。<br>我们再在 Spider里面输出修改后的状态码，在 parse() 方法中添加如下的输出语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.logger.debug（&apos;StatusCode:&apos; + str(response.status))</span><br></pre></td></tr></table></figure><p>重新运行之后，控制台输出了如下内容：<br><code>[httpbin] DEBUG: Status Code: 201</code></p><p> Response 的状态码成功修改了。<br>因此要想对 Response 进行后处理，就可以借助于<code>process_response()</code>方法</p><h3 id="SpiderMiddleware-用法🏳‍🌈"><a href="#SpiderMiddleware-用法🏳‍🌈" class="headerlink" title="SpiderMiddleware 用法🏳‍🌈"></a>SpiderMiddleware 用法🏳‍🌈</h3><p>Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。更多内容请看 Spider中间件(Middleware)<br>一句话总结就是：<code>处理解析部</code></p><h3 id="Item-PipeLine-用法🐱‍👓"><a href="#Item-PipeLine-用法🐱‍👓" class="headerlink" title="Item PipeLine 用法🐱‍👓"></a>Item PipeLine 用法🐱‍👓</h3><p>当spider爬取到item后，它被发送到项目管道（Item Pipeline），通过几个组件按顺序进行处理。每一个Item Pipeline是一个实现了简单方法的Python类，它接收到一个item并对其执行一个操作，也要决定该item是否应该继续通过管道，或者被丢弃，不再进行处理。</p><p><code>简单来说，我们通过爬虫爬取的项目，先交给项目管道，项目管道把数据处理处理(删除一些啦，存到mongodb啦)产生新的item</code></p><p><strong>Item Pipeline典型的用途是：</strong><br>1.清理HTML数据<br>2.验证爬取的数据(检查items是否包含某些字段)<br>3.检查副本(并删除它们)<br>4.将item数据存储在数据库中</p><p><code>每个Item Pipeline都是一个Python类</code>，它必须实现以下方法:</p><p><strong>process_item(self, item, spider)</strong></p><p>这个方法可以被每个Item Pipeline调用，process_item()必须是:返回一个字典类型数据、返回一个条目(或任何子类)对象，返回一个 Twisted Deferred 或者DropItem异常，丢弃的item不再由进一步的Item Pipeline处理。<br>参数含义：<br>item： Item对象或字典，爬取的item<br>spider：spider对象，爬取了这个item的spider<br>此外，他们还可以实现以下方法:</p><p><strong>open_spider(self, spider)</strong> -&gt;当spider打开时，函数就会被调用，spider参数含义：被打开的spider<br><strong>close_spider(self, spider)</strong>  -&gt;当spider关闭是，函数会被调用<br><strong>from_crawler(cls, crawler)</strong>  -&gt; 如果存在，这个类方法被调用来从一个Crawler创建一个spider实例。它必须返回管道的一个新实例，Crawler对象提供对所有的scrapy核心组件的访问，比如设置和信号;这是管道访问它们并将其功能连接到scrapy的一种方式。</p><hr><p>参考链接:</p><p>​              <a href="https://blog.csdn.net/xnby/article/details/52297047" target="_blank" rel="noopener">Scrapy进阶,middleware的使用</a></p><p>​              <a href="http://blog.51cto.com/linuxliu/2068601?wx" target="_blank" rel="noopener">运维学Python之爬虫高级篇</a></p><p>​              </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Scrapy是一个非常优秀的爬虫框架&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>不该死的人，还活着</title>
    <link href="httpsp://yoursite.com/2018/10/21/nuisance/"/>
    <id>httpsp://yoursite.com/2018/10/21/nuisance/</id>
    <published>2018-10-21T14:08:04.533Z</published>
    <updated>2018-10-21T14:08:15.830Z</updated>
    
    <content type="html"><![CDATA[<p>我再次体会到将要放弃的感觉，此刻我想的并不是，黑色成为黑色的原因，而是眼前的红色为什么这么刺眼。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我再次体会到将要放弃的感觉，此刻我想的并不是，黑色成为黑色的原因，而是眼前的红色为什么这么刺眼。&lt;br&gt;
    
    </summary>
    
    
      <category term="话" scheme="httpsp://yoursite.com/tags/%E8%AF%9D/"/>
    
  </entry>
  
  <entry>
    <title>qppium模拟---微信朋友圈</title>
    <link href="httpsp://yoursite.com/2018/10/20/wechatspider/"/>
    <id>httpsp://yoursite.com/2018/10/20/wechatspider/</id>
    <published>2018-10-20T14:38:13.269Z</published>
    <updated>2018-10-28T13:18:23.294Z</updated>
    
    <content type="html"><![CDATA[<p>初尝Android爬虫<br><a id="more"></a></p><h2 id="1-appium介绍"><a href="#1-appium介绍" class="headerlink" title="1. appium介绍"></a>1. appium介绍</h2><hr><p><a href="https://testerhome.com/wiki/appiumdoccn" target="_blank" rel="noopener">官方文档</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Appium is an open source test automation framework <span class="keyword">for</span> use with native <span class="keyword">and</span> hybrid mobile apps.</span><br></pre></td></tr></table></figure><p>如果说我们可以使用Selenium在web端对行为进行模拟，那么Appnium即是我们针对App的操作模拟器。</p><h2 id="2-爬取思路"><a href="#2-爬取思路" class="headerlink" title="2 . 爬取思路"></a>2 . 爬取思路</h2><hr><p>点击 Start Server按钮即可启动 Appium 的服务，相当于开启了一个 Appium 服务器。 我们可以通过 Appium 内置的驱动或 Python代码向 Appium 的服务器发送一系列操作指令， Appium 就会根据 不同的指令对移动设备进行驱动，完成不同的动作</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwhfvq2ynqj30m50kiwfv.jpg" alt=""></p><p>Appium 运行之后正在监听 4723 端口 。 我们可以向此端口对应的服务接口发送操作指令，此页面就会显示这个过程的操作日志</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwhfw7fi3fj30m30klgls.jpg" alt=""></p><p><em>开始连接</em></p><p>1.Android 手机通过数据线和运行 Appium 的 PC 相连，同时打开 USB 调试功能<br>2.cmd 输入<code>adb devices</code>，得到设备名称<br>3.配置Capability参数(如下图)，其中：<br>​     //  platformName： 它是平台名称，需要区分 Android 或 iOS，此处填写 Android<br>​     //  deviceName： 它是设备名称，此处是手机的具体类型。<br>​     //  appPackage： 它是 App 程序包名。通过cmd命令<code>adb shell pm list packages</code>可查<br>​     //  appActivity： 它是入口 Activity 名，这里通常需要以．开头。<br>4.start Session</p><p>​                                                    </p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fwhfwunwn5j31160jignb.jpg" alt=""></p><p> 到这里，我们可以在appium看到每块元素的id，xpath定位等信息， 同时，  tap(),click(),等动作函数，也给我们随心所欲的模拟提供空间。</p><p>就是<code>定位</code>+<code>获取</code>，并把获取内容存入MongoDB</p><p>//定位可通过 ID，或直接 XPATH 定位(事实上，appium很人性化的直接为用户提供了某元素的XPATH查找路径)</p><p>//截至10.23 0:17 仍未找到获取文本安卓元素对应的文本的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> appium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> appium.webdriver.common.touch_action <span class="keyword">import</span> TouchAction</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">from</span> processor <span class="keyword">import</span> Processor</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Moments</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 驱动配置</span></span><br><span class="line">        self.desired_caps = &#123;</span><br><span class="line">            <span class="string">'platformName'</span>: PLATFORM,</span><br><span class="line">            <span class="string">'deviceName'</span>: DEVICE_NAME,</span><br><span class="line">            <span class="string">'appPackage'</span>: APP_PACKAGE,</span><br><span class="line">            <span class="string">'appActivity'</span>: APP_ACTIVITY</span><br><span class="line">        &#125;</span><br><span class="line">        self.driver = webdriver.Remote(DRIVER_SERVER, self.desired_caps)</span><br><span class="line">        self.wait = WebDriverWait(self.driver, TIMEOUT)</span><br><span class="line">        self.client = MongoClient(MONGO_URL)</span><br><span class="line">        self.db = self.client[MONGO_DB]</span><br><span class="line">        self.collection = self.db[MONGO_COLLECTION]</span><br><span class="line">        <span class="comment"># 处理器</span></span><br><span class="line">        self.processor = Processor()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        登录微信</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 登录按钮</span></span><br><span class="line">        login = self.wait.until(EC.presence_of_element_located((By.ID, <span class="string">'com.tencent.mm:id/d75'</span>)))</span><br><span class="line">        login.click()</span><br><span class="line">        <span class="comment"># 手机输入</span></span><br><span class="line">        phone = self.wait.until(EC.presence_of_element_located((By.ID, <span class="string">'com.tencent.mm:id/hz'</span>)))</span><br><span class="line">        phone.set_text(USERNAME)</span><br><span class="line">        <span class="comment"># 下一步</span></span><br><span class="line">        next = self.wait.until(EC.element_to_be_clickable((By.ID, <span class="string">'com.tencent.mm:id/alr'</span>)))</span><br><span class="line">        next.click()</span><br><span class="line">        <span class="comment"># 密码</span></span><br><span class="line">        password = self.wait.until(</span><br><span class="line">            EC.presence_of_element_located((By.XPATH, <span class="string">'//*[@resource-id="com.tencent.mm:id/hz"][1]'</span>)))</span><br><span class="line">        password.set_text(PASSWORD)</span><br><span class="line">        <span class="comment"># 提交</span></span><br><span class="line">        submit = self.wait.until(EC.element_to_be_clickable((By.ID, <span class="string">'com.tencent.mm:id/alr'</span>)))</span><br><span class="line">        submit.click()</span><br><span class="line">        submit = self.wait.until(EC.element_to_be_clickable((By.ID, <span class="string">'com.tencent.mm:id/an3'</span>)))</span><br><span class="line">        submit.click()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enter</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        进入朋友圈</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 选项卡</span></span><br><span class="line">        tab = self.wait.until(</span><br><span class="line">            EC.presence_of_element_located((By.XPATH, <span class="string">'//android.widget.FrameLayout[@content-desc="当前所在页面,与wxid_br71rgy4kg5n22的聊天"]/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.view.ViewGroup/android.widget.FrameLayout[1]/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.RelativeLayout/android.widget.LinearLayout/android.widget.RelativeLayout[3]/android.widget.LinearLayout/android.widget.RelativeLayout/android.widget.ImageView'</span>)))</span><br><span class="line">        tab.click()</span><br><span class="line">        <span class="comment"># 朋友圈</span></span><br><span class="line">        moments = self.wait.until(EC.presence_of_element_located((By.ID, <span class="string">'com.tencent.mm:id/a7f'</span>)))</span><br><span class="line">        moments.click()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        爬取</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="comment"># 当前页面显示的所有状态</span></span><br><span class="line">            items = self.wait.until(</span><br><span class="line">                EC.presence_of_all_elements_located(</span><br><span class="line">                    (By.XPATH,<span class="string">'//android.widget.FrameLayout[@content-desc="当前所在页面,朋友圈"]/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.view.ViewGroup/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.RelativeLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.widget.ListView/android.widget.FrameLayout'</span>)))</span><br><span class="line">            <span class="comment"># 上滑</span></span><br><span class="line">            self.driver.swipe(FLICK_START_X, FLICK_START_Y + FLICK_DISTANCE, FLICK_START_X, FLICK_START_Y)</span><br><span class="line">            <span class="comment"># 遍历每条状态</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items:              </span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 昵称</span></span><br><span class="line">                    nickname = self.wait.until(</span><br><span class="line">                EC.presence_of_all_elements_located(</span><br><span class="line">                    (By.XPATH,<span class="string">'//android.widget.FrameLayout[@content-desc="当前所在页面,朋友圈"]/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.view.ViewGroup/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.RelativeLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.widget.ListView/android.widget.FrameLayout[1]/android.widget.LinearLayout/android.widget.RelativeLayout/android.widget.TextView'</span>))).text()</span><br><span class="line">                    <span class="comment"># 正文</span></span><br><span class="line">                    content = self.wait.until(</span><br><span class="line">                EC.presence_of_all_elements_located(</span><br><span class="line">                    (By.XPATH,<span class="string">'//android.widget.FrameLayout[@content-desc="当前所在页面,朋友圈"]/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.view.ViewGroup/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.RelativeLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.widget.ListView/android.widget.FrameLayout[1]/android.widget.LinearLayout/android.widget.LinearLayout[1]/android.widget.LinearLayout/android.view.View'</span>))).text()</span><br><span class="line">                    <span class="comment"># 日期</span></span><br><span class="line">                    date = self.wait.until(</span><br><span class="line">                EC.presence_of_all_elements_located(</span><br><span class="line">                    (By.XPATH,<span class="string">'//android.widget.FrameLayout[@content-desc="当前所在页面,朋友圈"]/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.view.ViewGroup/android.widget.FrameLayout/android.widget.FrameLayout/android.widget.RelativeLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.FrameLayout/android.widget.ListView/android.widget.FrameLayout[1]/android.widget.LinearLayout/android.widget.FrameLayout/android.widget.LinearLayout/android.widget.LinearLayout/android.widget.TextView'</span>))).text()</span><br><span class="line">                    <span class="comment"># 处理日期</span></span><br><span class="line">                    date = self.processor.date(date)</span><br><span class="line">                    print(<span class="string">'一次insert记录'</span>)</span><br><span class="line">                    print(nickname, content, date)</span><br><span class="line">                    data = &#123;</span><br><span class="line">                        <span class="string">'nickname'</span>: nickname,</span><br><span class="line">                        <span class="string">'content'</span>: content,</span><br><span class="line">                        <span class="string">'date'</span>: date,</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment"># 插入MongoDB</span></span><br><span class="line">                    self.collection.update(&#123;<span class="string">'nickname'</span>: nickname, <span class="string">'content'</span>: content&#125;, &#123;<span class="string">'$set'</span>: data&#125;, <span class="keyword">True</span>)</span><br><span class="line">                    sleep(SCROLL_SLEEP_TIME)</span><br><span class="line">                <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        入口</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 登录</span></span><br><span class="line">        self.login()</span><br><span class="line">        <span class="comment"># 进入朋友圈</span></span><br><span class="line">        self.enter()</span><br><span class="line">        <span class="comment"># 爬取</span></span><br><span class="line">        self.crawl()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    moments = Moments()</span><br><span class="line">    moments.main()</span><br></pre></td></tr></table></figure><p>对朋友圈时间进行处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Processor</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">date</span><span class="params">(self, datetime)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        处理时间</span></span><br><span class="line"><span class="string">        :param datetime: 原始时间</span></span><br><span class="line"><span class="string">        :return: 处理后时间</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">'\d+分钟前'</span>, datetime):</span><br><span class="line">            minute = re.match(<span class="string">'(\d+)'</span>, datetime).group(<span class="number">1</span>)</span><br><span class="line">            datetime = time.strftime(<span class="string">'%Y-%m-%d'</span>, time.localtime(time.time() - float(minute) * <span class="number">60</span>))</span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">'\d+小时前'</span>, datetime):</span><br><span class="line">            hour = re.match(<span class="string">'(\d+)'</span>, datetime).group(<span class="number">1</span>)</span><br><span class="line">            datetime = time.strftime(<span class="string">'%Y-%m-%d'</span>, time.localtime(time.time() - float(hour) * <span class="number">60</span> * <span class="number">60</span>))</span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">'昨天'</span>, datetime):</span><br><span class="line">            datetime = time.strftime(<span class="string">'%Y-%m-%d'</span>, time.localtime(time.time() - <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>))</span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">'\d+天前'</span>, datetime):</span><br><span class="line">            day = re.match(<span class="string">'(\d+)'</span>, datetime).group(<span class="number">1</span>)</span><br><span class="line">            datetime = time.strftime(<span class="string">'%Y-%m-%d'</span>, time.localtime(time.time()) - float(day) * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>)</span><br><span class="line">        <span class="keyword">return</span> datetime</span><br></pre></td></tr></table></figure><p>—未完待续</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;初尝Android爬虫&lt;br&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB</title>
    <link href="httpsp://yoursite.com/2018/10/20/MongoDB/"/>
    <id>httpsp://yoursite.com/2018/10/20/MongoDB/</id>
    <published>2018-10-20T07:11:28.435Z</published>
    <updated>2018-10-20T09:45:36.168Z</updated>
    
    <content type="html"><![CDATA[<p><em>什么是MongoDB?我们又该去怎样使用它？</em></p><a id="more"></a><p><code>已删</code></p><p><a href="https://www.runoob.com/mongodb" target="_blank" rel="noopener">MongoDB官方文档</a></p><p><a href="https://blog.csdn.net/callinglove/article/details/45668673?utm_source=blogxgwz0" target="_blank" rel="noopener">PyMongo是在Python环境下使用MongoDB的语言</a></p><p>写了一半，忽然觉得，针对 那些[工具性的]，就老老实实把官方的文档看懂。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;什么是MongoDB?我们又该去怎样使用它？&lt;/em&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="httpsp://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>写在学习代理池和cookie池之后</title>
    <link href="httpsp://yoursite.com/2018/10/08/sougoupachong/"/>
    <id>httpsp://yoursite.com/2018/10/08/sougoupachong/</id>
    <published>2018-10-08T15:33:42.293Z</published>
    <updated>2018-10-20T09:54:19.440Z</updated>
    
    <content type="html"><![CDATA[<p>有关基本思路的描述</p> <a id="more"></a><p>这篇博客的目的是，尝试搞懂我最近做了什么.</p><p>我们为什么要用代理池？<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">部分网站有反爬虫措施，当我们使用一个ip地址对该网站进行过多的访问时，会被反爬虫机制自动视为爬虫，从而ip拉黑.</span><br></pre></td></tr></table></figure><p>代理池的构建是怎样的？<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">对网上的免费ip代理网站进行爬取(西刺，proxy360)，它们网站的ip源是完全暴露在网页源码上的，我们只用简单的进行分析，就可以拿到足够的ip.</span><br></pre></td></tr></table></figure><p>如此一来，思路很清晰，设计一个爬虫，针对几个免费的网站解析爬取，将拿到 ip 进行筛选，排名，存入数据库。  并可以实现获取接口，即调即用。</p><p><code>基本模块分为 4块：存储模块、获取模块、检测模块、接口模块</code></p><p>###</p><ol><li><p>存储模块： 负责存储抓取下来的代理。 首先要保证代理不重复， 要标识代理的可用情况，还 要动态实时处理每个代理，所以一种比较高效和方便的存储方式就是使用 Redis 的 Sorted Set，即有序集合。</p></li><li><p>获取模块： 需要定时在各大代理网站抓取代理。 代理可以是免费公开代理也可以是付费代 理，代理的形式都是 IP 加端口，此模块尽量从不同来源获取，尽量抓取高匿代理，抓取成功 之后将可用代理保存到数据库中。 </p></li><li><p>检测模块： 需要定时检测数据库中的代理。 这里需要设置一个检测链接，最好是爬取哪个网 站就检测哪个网站，这样更加有针对性，如果要做一个通用型的代理，那可以设置百度等链 接来检测。 另外，我们需要标识每一个代理的状态，如设置分数标识， 100 分代表可用，分 数越少代表越不可用。 检测一次，如果代理可用，我们可以将分数标识立即设置为 100 满 分，也可以在原基础上加 l分；如果代理不可用，可以将分数标识减 l 分，当分数戚到一定阔 值后，代理就直接从数据库移除。 通过这样的标识分数，我们就可以辨别代理的可用情况， 选用的时候会更有针对性。 </p></li><li><p>接口模块： 需要用 API 来提供对外服务的接口 。 其实我们可以直接连接数据库采取对应的数 据，但是这样就需要知道数据库的连接信息，并且要配置连接，而比较安全和方便的方式就 是提供一个 Web API 接口，我们通过访问接口即可拿到可用代理。 另外，由于可用代理可能 有多个，那么我们可以设置一个随机返回某个可用代理的接口，这样就能保证每个可用代理 都可以取到，实现负载均衡</p></li></ol><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fw7uv32bfaj30px0cfahk.jpg" alt=""></p><p><a href="https://github.com/Python3WebSpider/ProxyPool" target="_blank" rel="noopener">我们需要自己造轮子吗</a>  我觉得这要分情况。 </p><p><br><br></p><p>我们为什么要使用cookie池</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cookies是我们登陆一个页面的接口，不登陆固然可以获取网页源码，但是会受访问限制，以及不具有一些页面的权限，比如微博来说，我们的cookie池实际上就是多个微博账号的信息。</span><br></pre></td></tr></table></figure><p>与上面ip池的搭建差别是一些微博账号是我们需要自己通过某些渠道购买的。</p><p><a href="https://github.com/Python3WebSpider/CookiesPool" target="_blank" rel="noopener">轮子</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有关基本思路的描述&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>python の __new__()</title>
    <link href="httpsp://yoursite.com/2018/10/07/python_new/"/>
    <id>httpsp://yoursite.com/2018/10/07/python_new/</id>
    <published>2018-10-07T09:28:04.356Z</published>
    <updated>2018-10-09T14:14:49.151Z</updated>
    
    <content type="html"><![CDATA[<p><code>在学习代理池中，发现了自己搁置的问题。我尝试通过这篇文章，来理清   __ new __  () 和 __ init __()的关系.</code></p> <a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span><span class="params">(object)</span>:</span></span><br><span class="line">    price = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">how_much_of_book</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        print(self)</span><br><span class="line">        <span class="keyword">return</span> self.price * n</span><br><span class="line"></span><br><span class="line">foo = Foo()</span><br><span class="line">print(foo.how_much_of_book(<span class="number">8</span>))</span><br><span class="line">print(dir(Foo))</span><br></pre></td></tr></table></figure><p>⬆⬆⬆分析上面的代码，这个类实例化过程，Foo类继承object类，继承了object的<strong>new</strong>方法。当你没有重载这个方法(通俗来说，<code>你没有在Foo类中没有写__new__方法)</code>，Foo实例化是默认自动调用父类<strong>new</strong>方法，这个方法返回值为类的实例，也就是self, 用来提供这个函数的第一个参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span><span class="params">(object)</span>:</span></span><br><span class="line">    price = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, *agrs, **kwds)</span>:</span></span><br><span class="line">        inst = object.__new__(cls, *agrs, **kwds)</span><br><span class="line">        print(inst)</span><br><span class="line">        <span class="keyword">return</span> inst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">how_much_of_book</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        print(self)</span><br><span class="line">        <span class="keyword">return</span> self.price * n</span><br><span class="line"></span><br><span class="line">foo = Foo()</span><br><span class="line">print(foo.how_much_of_book(<span class="number">8</span>))</span><br><span class="line"><span class="comment"># &lt;__main__.Foo object at 0x1006f2750&gt;</span></span><br><span class="line"><span class="comment"># &lt;__main__.Foo object at 0x1006f2750&gt;</span></span><br><span class="line"><span class="comment"># 400</span></span><br></pre></td></tr></table></figure><p>⬆⬆⬆请看上面代码，Foo类中重载了<strong>new</strong>方法，它的返回值为Foo类的实例对象</p><hr><p><code>_init__ 方法为初始化方法，为类的实例提供一些属性或完成一些动作</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, *agrs, **kwds)</span>:</span></span><br><span class="line">        inst = object.__new__(cls, *agrs, **kwds)</span><br><span class="line">        print(inst)</span><br><span class="line">        <span class="keyword">return</span> inst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, price=<span class="number">50</span>)</span>:</span></span><br><span class="line">        self.price = price</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">how_much_of_book</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        print(self)</span><br><span class="line">        <span class="keyword">return</span> self.price * n</span><br><span class="line"></span><br><span class="line">foo = Foo()</span><br><span class="line">print(foo.how_much_of_book(<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;__main__.Foo object at 0x1006f2750&gt;</span></span><br><span class="line"><span class="comment"># &lt;__main__.Foo object at 0x1006f2750&gt;</span></span><br><span class="line"><span class="comment"># 400</span></span><br></pre></td></tr></table></figure><p>那么说到这里，我们用两句话来总结就是:</p><p>⭐<strong>new</strong> 方法创建实例对象供<strong>init</strong> 方法使用，<strong>init</strong>方法定制实例对象。</p><p><strong>⭐new</strong> 方法必须返回值，<strong>init</strong>方法不需要返回值。(如果返回非None值就报错)</p><p><br><br></p><p>我们举两个例子，观察New的常见两种用法</p><p>第一： 继承不可变数据类型时需要用到<strong>new</strong>方法(like int, str, or tuple） </p><p> 将英寸转化成米</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Inch(float):</span><br><span class="line">    &quot;Convert from inch to meter&quot;</span><br><span class="line">    def __new__(cls, arg=0.0):</span><br><span class="line">        return float.__new__(cls, arg*0.0254)</span><br><span class="line"></span><br><span class="line">print(Inch(12))</span><br></pre></td></tr></table></figure><p><br></p><p>第二:   用在元类，定制创建类对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="string">'''来自http://eli.thegreenplace.net/2011/08/14/python-metaclasses-by-example'''</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MetaClass</span><span class="params">(type)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(meta, name, bases, dct)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'-----------------------------------'</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Allocating memory for class"</span>, name</span><br><span class="line">        <span class="keyword">print</span> meta</span><br><span class="line">        <span class="keyword">print</span> bases</span><br><span class="line">        <span class="keyword">print</span> dct</span><br><span class="line">        <span class="keyword">return</span> super(MetaClass, meta).__new__(meta, name, bases, dct)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(cls, name, bases, dct)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'-----------------------------------'</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Initializing class"</span>, name</span><br><span class="line">        <span class="keyword">print</span> cls</span><br><span class="line">        <span class="keyword">print</span> bases</span><br><span class="line">        <span class="keyword">print</span> dct</span><br><span class="line">        super(MetaClass, cls).__init__(name, bases, dct)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Myclass</span><span class="params">(object)</span>:</span></span><br><span class="line">    __metaclass__ = MetaClass</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(self, param)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> param</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Myclass()</span><br><span class="line">p.foo(<span class="string">"hello"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------</span></span><br><span class="line"><span class="comment"># Allocating memory for class Myclass</span></span><br><span class="line"><span class="comment"># &lt;class '__main__.MetaClass'&gt;</span></span><br><span class="line"><span class="comment"># (&lt;type 'object'&gt;,)</span></span><br><span class="line"><span class="comment"># &#123;'__module__': '__main__', 'foo': &lt;function foo at 0x1007f6500&gt;, '__metaclass__': &lt;class '__main__.MetaClass'&gt;&#125;</span></span><br><span class="line"><span class="comment"># -----------------------------------</span></span><br><span class="line"><span class="comment"># Initializing class Myclass</span></span><br><span class="line"><span class="comment"># &lt;class '__main__.Myclass'&gt;</span></span><br><span class="line"><span class="comment"># (&lt;type 'object'&gt;,)</span></span><br><span class="line"><span class="comment"># &#123;'__module__': '__main__', 'foo': &lt;function foo at 0x1007f6500&gt;, '__metaclass__': &lt;class '__main__.MetaClass'&gt;&#125;</span></span><br><span class="line"><span class="comment"># hello</span></span><br></pre></td></tr></table></figure><p><code>Myclass相当于 拷贝了 MetaClass 的方法，MetaClass 的种类仍然是 MetaClass，定制的init 的种类 也自然是Myclass</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;在学习代理池中，发现了自己搁置的问题。我尝试通过这篇文章，来理清   __ new __  () 和 __ init __()的关系.&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="httpsp://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>关于海</title>
    <link href="httpsp://yoursite.com/2018/10/07/photo/"/>
    <id>httpsp://yoursite.com/2018/10/07/photo/</id>
    <published>2018-10-07T08:57:03.798Z</published>
    <updated>2018-10-09T15:27:18.878Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://wx4.sinaimg.cn/mw690/6c3e6b13gy1fvyja7cikaj20uk0kedj0.jpg" alt=""><br><a id="more"></a><br><img src="https://wx3.sinaimg.cn/mw690/006lRDaTgy1fw2apaw5nlj32ro1ugnpe.jpg" alt=""><br><br><br><br><br><!--more--></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://wx4.sinaimg.cn/mw690/6c3e6b13gy1fvyja7cikaj20uk0kedj0.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="话" scheme="httpsp://yoursite.com/tags/%E8%AF%9D/"/>
    
  </entry>
  
  <entry>
    <title>GEETEST滑动验证码破解</title>
    <link href="httpsp://yoursite.com/2018/10/04/huadongpojie/"/>
    <id>httpsp://yoursite.com/2018/10/04/huadongpojie/</id>
    <published>2018-10-04T10:44:21.396Z</published>
    <updated>2018-10-20T09:56:17.090Z</updated>
    
    <content type="html"><![CDATA[<p>验证码的破解，是网站爬虫正常运行所必须具备的功能。</p><a id="more"></a>   <p> 注: 本文针对[<em>滑动验证被切割随机打乱，并根据源码中 <strong>&lt; DIV &gt;</strong> 标签顺序进行 <strong>取块排列</strong>  验证情况 ，属于常见的一种混淆方式</em>]</p><hr><p>关键词：</p><ol><li><strong><a href="#1" target="_self">图像分析</a></strong></li><li><strong><a href="#2" target="_self">图像拼接</a></strong></li></ol><p id="1"><br>图像分析:</p><p>   &nbsp;&nbsp; 我们以<a href="https://www.huxiu.com/" target="_blank" rel="noopener">虎嗅网</a>登陆页面为例，我们在输入手机注册前，需要通过一个滑动式的 <em>captcha</em> ,我们可以通过<code>webdriver.chrome  + selenium</code> 来模拟拖动，问题就在于究竟要拖动多远？拖动的距离究竟是多少？(offset 究竟是多少？)</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fvxl234pokj30dg07w76i.jpg" alt="这是截图"></p><p>   &nbsp;&nbsp;仔细一想，如果有一个不存在缺口的<strong>源图片</strong>，那就舒服了，因为那样的话，我们只需比较，<code>源图哪些像素块，比上面的图形颜色更深，从而判断出深颜色缺口的位置</code>,这样我们就得到了，需要模拟拖动的距离了。那么从哪里可以得到原始图片呢？<br>   F12审查代码时，发现了这样两个&lt; div&gt;:</p><p><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fvxku4epdej31620ew0uu.jpg" alt="黄线标出"></p><p>我们打开后发现，里面图片链接全部指向各自的那一个图片，<a href="http://ww1.sinaimg.cn/large/006YPp6gly1fvxkuhcc8ij31630iq41p.jpg" target="_blank" rel="noopener">一个长这样</a>,<a href="http://ww1.sinaimg.cn/large/006YPp6gly1fvxkxx3xzuj30kc0doabb.jpg" target="_blank" rel="noopener">一个长这样</a>,这，这！这不就是有缺口和没缺口的图片吗？</p><p></p><p id="2"> <br><br> 图像拼接:</p><br>等等，为什么乱了？<p></p><p>对，如果我们仔细观察，我们发现图片是被切割打乱了的，而且，我们判断，如果想得到原图，一定是要像拼积木一样把这些小块重新排列组合,那么，有什么规律在其中呢？我们该怎样一个一个拼呢？<br>其实，不难发现，我们在打开那两个标签后，我们发现一些整整齐齐的从上到下的标签，并且还有   <code>position</code>属性，x,值以12为差，最小1 最大 277，但y只有 0 或 58，由此分析出，从上到下，是我们取积木的顺序，取打乱图的第一个(x,y)坐标点对应处的一块积木，然后拼接到一个空白框的左上角，然后接着从乱图里面取出第二个位置的积木，紧挨着刚才那一个向右，此行满了换下一行，以此类推,最终得到一个完整图。<br>这样的话，我们的分析就结束了，然后我们通过像素比较就可以找出，缺口的位置，然后模拟拖动就ok了。<br>注意，实际应用中，我们需要实验性模拟拖动几次，再对拖动距离distance进行微修正，从而提高准确率。<br><br><br><br><a href="https://paste.ubuntu.com/p/y7PSVFdxsJ/" target="_blank" rel="noopener">源码</a><br><br><br><a href="https://www.jianshu.com/p/c8df1194b514" target="_blank" rel="noopener">参考博客</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;验证码的破解，是网站爬虫正常运行所必须具备的功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="httpsp://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>快速熟悉 markdown</title>
    <link href="httpsp://yoursite.com/2018/10/02/learn_MarkDown/"/>
    <id>httpsp://yoursite.com/2018/10/02/learn_MarkDown/</id>
    <published>2018-10-02T12:24:50.086Z</published>
    <updated>2018-10-09T13:56:34.248Z</updated>
    
    <content type="html"><![CDATA[<p><em>快速熟悉</em><br>   <strong><em>markdown</em></strong></p><a id="more"></a>        <hr><blockquote><p>我们可以使用  <strong>大于号</strong> ，来表示引用</p></blockquote><p><del>我们在文本两边，加上一对双波浪号，就得到删除特效</del></p><p><a href="http://www.baidu.com" target="_blank" rel="noopener">方框内部是文本,点击跳转百度</a><br><img src="http://ww1.sinaimg.cn/large/006YPp6gly1fvu4hphapdj307g08edh6.jpg" alt="如果框起前面加个感叹号，代表我要加图片图片"><br>倘若我先写三个井号，代表我要开始<strong>列表</strong>，*、+号带领无序，1.带领有序</p><p>###</p><ul><li>k1</li><li>k2</li><li>k3</li></ul><ol><li>l1</li><li>l2</li><li>l3<br>###<br>一对反引号可以生成一个<code>背景加深</code>，这很讨喜<br>且表格的创建，格外方便，只用添加一点  |:—-: |这表明，我正在写表格<br>|电影|导演|评分|<br>|:—-:|:—-:|:—-:|<br>|天注定|贾樟柯|未知|<br>|江湖儿女|贾樟柯|未知|<br>|三峡好人|贾樟柯|未知|<br>|站台|贾樟柯|未知|</li></ol><p>我们规定用三个反引号括住代码块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">const unsigned long int a ;</span><br><span class="line">a = inf ;</span><br></pre></td></tr></table></figure></p><p><a href="http://ww1.sinaimg.cn/large/006YPp6gly1fvu792e3vuj30wx0npmz5.jpg" target="_blank" rel="noopener">点击查看源码图</a><br><a href="http://ww1.sinaimg.cn/large/006YPp6gly1fvu6opl5ytj30j80ofagp.jpg" target="_blank" rel="noopener">点击查看效果图</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;快速熟悉&lt;/em&gt;&lt;br&gt;   &lt;strong&gt;&lt;em&gt;markdown&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="httpsp://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Hexo 更换主题</title>
    <link href="httpsp://yoursite.com/2018/09/29/newtheme/"/>
    <id>httpsp://yoursite.com/2018/09/29/newtheme/</id>
    <published>2018-09-29T15:13:40.218Z</published>
    <updated>2018-10-09T15:01:21.150Z</updated>
    
    <content type="html"><![CDATA[<p>简短的关于Hexo主题更新配置的说明<br>当你需要更换自己的博客主题时，你需要这样做：<br> <a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">$ git clone https://*********</span><br><span class="line">$ npm install hexo-renderer-pug --save</span><br><span class="line">$ npm install hexo-renderer-sass --save   #下载主题文件和渲染器，如果在下载第三个文件的过程中报错，你可以试试npm国内镜像，或科学上网。</span><br><span class="line"></span><br><span class="line">theme: ****        #打开根目录下的_config.yml,并找到 theme关键字，更新自己主题名称</span><br><span class="line">$ hexo clean</span><br><span class="line">$ hexo g           # 生成静态页面</span><br><span class="line">$ hexo d           # 上传到github</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简短的关于Hexo主题更新配置的说明&lt;br&gt;当你需要更换自己的博客主题时，你需要这样做：&lt;br&gt;
    
    </summary>
    
    
      <category term="工具" scheme="httpsp://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
</feed>
